### Data Augmentation
1. Language Models are Realistic Tabular Data Generators (https://github.com/kathrinse/be_great) https://arxiv.org/abs/2210.06280


### Word Embeddings
1. Deciphering microbial gene function using natural langauge processing https://doi.org/10.1038/s41467-022-33397-4
2. Vector-clustering Multiple Sequence Alignment: Aligning into the twilight zone of protein sequence similarity with protein language models https://doi.org/10.1101/2022.10.21.513099


### BERT
1. Foundation Transformer https://arxiv.org/abs/2210.06423
2. ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Proterty Prediction (https://github.com/seyonechithrananda/bert-loves-chemistry) https://arxiv.org/abs/2010.09885
3. ProteinBERT: a universal deep-learning model of protein sequence and function (https://github.com/nadavbra/protein_bert) https://doi.org/10.1093/bioinformatics/btac020
4. Single-sequence protein struture prediction using a langauge model and deep  https://doi.org/10.1038/s41587-022-01432-w


### Large Langauge Models
1. AlphaFold's new rival? Meta AI predicts shape of 600 million proteins (ESMFold: https://www.nature.com/articles/d41586-022-03539-1)
    a. Evolutionary-scale prediction of atomic level protein structure with a language model (https://doi.org/10.1101/2022.07.20.500902)
    b. Language models of protein sequences at the scale of evolution enable accurate structure prediction (https://doi.org/10.1101/2022.07.20.500902)

2. 